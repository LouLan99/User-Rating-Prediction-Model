{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our analysis, we discover that most of the applications are rated around 3 but we have some of the applications that are not rated which is good part of the data (25% of Rating corresponds to non-rated applications). \n",
    "\n",
    "For our categorical columns, we saw that that most of the applications are for everyone, free and contains ads. We saw that the applications categorize Adventure, Role Playing, Casino have higher rating. Application for everyone seems to be rated lower compare to its other content rating features. \n",
    "\n",
    "We also discover that the free application tends to be rated lower which might be due to ads as most of the free application contain ads and if there are too many ads the application is not really enjoyable to use but we saw that ad supported application seems to be rated higher compare to the non-ad supported application supposing that the applications doesnâ€™t contains as much ads and it not a big problem for the user. \n",
    "\n",
    "Using a heatmap, we saw that our target variable is not really correlated with the other columns. \n",
    "\n",
    "When we did our baseline modelling, we saw that our first model, the Linear Regression model was not fitted. We then used pipeline and gridsearh to find the best parameters to tuned our model, we could a small increase but the model was still not fitted (we passed from a negative number to 0.06). We could also see that our residual bar chat was not distributed. \n",
    "\n",
    "For our second baseline modelling we decide to choose the Decision Tree Regressor. We could see that the model was fitted as the score was 0.94 meaning that the model was fitted and was indeed well predictive. Then we tried to use pipeline and gridsearh to find the best parameters to tuned our model, we did 4 different testing: 2 without PCA where we used broad and tuned parameters and then we did 2 tests using PCA using broad and tuned parameters. The result where the same from the baseline model for our test without pca (score 0.94) and we use feature importance where the Rating count seems to have the largest variance. For the 2 other test with PCA, the broad parameters had the score of 0.86 and the feature performance were PC5 and PC6 while the tunes parameters had the score of 0.87 which is slightly better that our broad parameters and the feature importance where PC5 and PC2. \n",
    "\n",
    "To wrap up our analysis our best model is the Decision Tree Regressor without the PCA and the Rating count seems to be our most predictive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next we would like to work on an API / product\n",
    "Try different model such as neural network\n",
    "If we could have made different step (and if we had more time), used the models without the non-rated application. \n",
    "A different data processing such as dropping less columns meaning more cleaning and preprocessing \n",
    "if we had a review column with text, we could have used a different model and have a natural language processing (NLP) approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotly_bokeh",
   "language": "python",
   "name": "plotly_bokeh"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
